import os
import pandas as pd
import streamlit as st
from openai import OpenAI
from elasticsearch import Elasticsearch

client = OpenAI(api_key=st.secrets["api_key"])

# https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud#finding-your-cloud-id
ELASTIC_CLOUD_ID = st.secrets["elastic_cloud_key"]

# https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud#creating-an-api-key
ELASTIC_API_KEY = st.secrets["elastic_api_key"]

es = Elasticsearch(
  cloud_id = ELASTIC_CLOUD_ID,
  api_key=ELASTIC_API_KEY
)

# Test connection to Elasticsearch
print(es.info())


st.subheader("ğŸ‘ğŸ‘ğŸ‘ì˜ë¬¸ ìœ„í‚¤í”¼ë””ì•„ ì´ìš©í•œ")
st.title("í•œê¸€ë¡œ ë‹µë³€í•˜ëŠ” AI")
st.subheader("ë¶€ì œ : Semantic search and Retrieval augmented generation using Elasticsearch and OpenAI")

st.caption('''
ì˜ë¬¸ Wikiì—ì„œ ë‹µë³€ ê°€ëŠ¥í•œ ì§ˆë¬¸ì— ëŒ€í•´ì„œ ë‹µë³€ì„ ì˜í•©ë‹ˆë‹¤. ì¡¸ì€ ì§ˆë¬¸ ì˜ˆ : 
- ëŒ€ì„œì–‘ì€ ëª‡ ë²ˆì§¸ë¡œ í° ë°”ë‹¤ì¸ê°€?
- ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ”?
- ì´ìˆœì‹ ì˜ ì¶œìƒë…„ë„ëŠ”?
- ë„ìš”íƒ€ì—ì„œ ê°€ì¥ ë§ì´ íŒ”ë¦¬ëŠ” ì°¨ëŠ”?

ë°ì´í„° ì¶œì²˜
- https://cdn.openai.com/API/examples/data/vector_database_wikipedia_articles_embedded.zip
- ë°ì´í„° ì„¤ëª… : https://weaviate.io/developers/weaviate/tutorials/wikipedia
- ë°ì´í„° ê±´ìˆ˜ : 25,000ê±´ (ë°ì´í„°ì˜ ì–‘ì„ ëŠ˜ë¦¬ë©´, ë‹¤ì–‘í•œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ê°€ëŠ¥)

''')

with st.form("form"):
    question = st.text_input("Prompt")
    submit = st.form_submit_button("Submit")

if submit and question:
  with st.spinner("Waiting for Kevin AI..."):
      print("ì§ˆë¬¸ : " + question)
      question = question.replace("\n", " ")
    
      question = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
              {"role": "user", "content": "If a question comes in Korean, Translate the following Korean text to Enaglish:"
               + question},
          ]
      )
      question = question.choices[0].message.content
      print("ë²ˆì—­ : " + question)
      question_embedding = client.embeddings.create(input = [question], model="text-embedding-ada-002").data[0].embedding
    
      response = es.search(
        index = "wikipedia_vector_index",
        knn={
            "field": "content_vector",
            "query_vector":  question_embedding,
            "k": 10,
            "num_candidates": 100
          }
      )

      top_hit_summary = response['hits']['hits'][0]['_source']['text'] # Store content of top hit for final step

      summary = client.chat.completions.create(
        model="gpt-3.5-turbo",
        #model="gpt-4-1106-preview",
        messages=[
              #{"role": "system", "content": "You are a helpful assistant. If it is difficult to give an exact answer to the question with the following text, please answer in Korean: 'ì œê°€ ê¸°ì§€ê³  ìˆëŠ” ì •ë³´ë¡œëŠ” ë‹µë³€ì´ ì–´ë µìŠµë‹ˆë‹¤.'"},
              {"role": "system", "content": "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know."},

              #{"role": "system", "content": "You are a helpful assistant."},
              #{"role": "user", "content": "Translate the following question into english and answer in Korean:"
              #{"role": "user", "content": "Answer the following question in korean:"
              # + question
              # + "by using the following text:"
              # + top_hit_summary},
              {"role": "user", "content": "Use three sentences maximum and keep the answer concise and Answer in korean: Question: "
               + question +
               " Context: " + top_hit_summary },
          ]
      )

    
      choices = summary.choices
      st.divider()
    
      for choice in choices:
        print(choice.message.content)
        st.markdown(choice.message.content)

      st.divider()
      st.subheader("ê²€ìƒ‰í•´ë³¸ ìœ„í‚¤ ë¬¸ì„œ List")
    
      for hit in response['hits']['hits']:
        id = hit['_id']
        score = hit['_score']
        title = hit['_source']['title']
        url = hit['_source']['url']
        pretty_output = (f"\nID: {id}\nTitle: {title}\nUrl: {url}\nScore: {score}")
        st.markdown(pretty_output)
